---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hello! 

I am a robot vision researcher interested in building object-centric 3D representations as the foundation for robot perception, reasoning, and action. My work focuses on developing robust spatial understanding, such as geometry, pose, physical properties, and dynamics models, in visually challenging environments by incorporating data-driven 3D priors and real-world structures, such as symmetry and physics. My goal is to enable efficient and generalizable robot operation in cluttered environments.

My research explores two main directions:
- Leveraging symmetry as a strong prior for efficient and reliable world understanding. 
- Test-time update of scene understanding through embodied interactions and physics-based reasoning. 

I am currently a Postdoctoral Researcher at the GRASP Lab, University of Pennsylvania, advised by [Michael Posa](https://www.grasp.upenn.edu/people/michael-posa/), and an Assistant Research Scientist at the University of Michigan, advised by [Maani Ghaffari](https://name.engin.umich.edu/people/ghaffari-maani/). I received my Ph.D. in Mechanical Engineering from the University of Michigan, advised by [Huei Peng](https://huei.engin.umich.edu/) and Maani Ghaffari. 

Please check out my [Google Scholar](https://scholar.google.com/citations?user=70CbUXwAAAAJ&hl=en) page for the full list of my publications. 

Selected Work
======
<div style="display: flex; align-items: center; margin-bottom: 20px;">
    <div style="flex: 0 0 150px;">
        <img src="..\images\thumbnails\obj_3dgen.png" alt="Vysics Thumbnail" style="width: 150px; height: auto;">
    </div>
    <div style="flex: 1; padding-left: 20px;">
        <h3>Object Reconstruction under Occlusion with Generative Priors and
 Contact-induced Constraints</h3>
        <p>
            <strong>Minghan Zhu</strong>, Zhiyi Wang, Qihang Sun, Maani Ghaffari, Michael Posa<br>
            <!-- <em>Robotics: Science and Systems (RSS), 2025</em> -->
        </p>
        <p>
            (Under review)
        </p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
    <div style="flex: 0 0 150px;">
        <img src="..\images\thumbnails\reln.png" alt="Vysics Thumbnail" style="width: 150px; height: auto;">
    </div>
    <div style="flex: 1; padding-left: 20px;">
        <h3>Equivariant Neural Networks for General Linear Symmetries on Lie Algebras</h3>
        <p>
            Chankyo Kim, Sicheng Zhao, <strong>Minghan Zhu</strong>, Tzu-Yuan Lin, Maani Ghaffari<br>
            <!-- <em>Robotics: Science and Systems (RSS), 2025</em> -->
        </p>
        <p>
            (Under review)
        </p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
    <div style="flex: 0 0 150px;">
        <img src="..\images\thumbnails\vysics.png" alt="Vysics Thumbnail" style="width: 150px; height: auto;">
    </div>
    <div style="flex: 1; padding-left: 20px;">
        <h3>Vysics: Object Reconstruction Under Occlusion by Fusing Vision and Contact-Rich Physics</h3>
        <p>
            Bibit Bianchini*, 
            <strong>Minghan Zhu*</strong>,
            Mengti Sun, 
            Bowen Jiang,
            Camillo J. Taylor, 
            Michael Posa <br>
            <em>Robotics: Science and Systems (RSS), 2025</em>
        </p>
        <p>
            <a href="https://arxiv.org/abs/2504.18719">Paper</a>  
            | <a href="https://vysics-vision-and-physics.github.io/">Project</a>
        </p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
    <div style="flex: 0 0 150px;">
        <img src="..\images\thumbnails\lidarar_thumbnail.png" alt="SE3ET Thumbnail" style="width: 150px; height: auto;">
    </div>
    <div style="flex: 1; padding-left: 20px;">
        <h3>LiDAR-EDIT: LiDAR Data Generation by Editing the Object Layouts in Real-World Scenes</h3>
        <p>
            Shing-Hei Ho, 
            Bao Thach,
            <strong>Minghan Zhu</strong> <br>
            <em>IEEE International Conference on Robotics & Automation (ICRA), 2025</em>
        </p>
        <p>
            <a href="https://arxiv.org/abs/2410.11783">Paper</a>  
            | <a href="https://sites.google.com/view/lidar-edit">Project</a>  
            | <a href="https://huggingface.co/spaces/Shing-Hei/LiDAR-EDIT_DEMO_ICRA2025">Demo</a>  
            | <a href="https://github.com/HoAdrian/ICRA2025_lidar_edit">Code</a>  
            <!-- | <a href="link-to-bibtex">BibTeX</a> -->
        </p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
    <div style="flex: 0 0 150px;">
        <img src="..\images\thumbnails\latentbki.png" alt="SE3ET Thumbnail" style="width: 150px; height: auto;">
    </div>
    <div style="flex: 1; padding-left: 20px;">
        <h3>LatentBKI: Open-Dictionary Continuous Mapping in Visual-Language Latent Spaces With quantifiable uncertainty</h3>
        <p>
            Joey Wilson, Ruihan Xu, Yile Sun, Parker Ewen, <strong>Minghan Zhu</strong>, Kira Barton, Maani Ghaffari <br>
            <em>IEEE Robotics and Automation Letters, 2025</em>
        </p>
        <p>
            <a href="https://arxiv.org/abs/2412.00592">Paper</a>  
            | <a href="https://github.com/UMich-CURLY/LatentBKI">Code</a>  
            <!-- | <a href="link-to-bibtex">BibTeX</a> -->
        </p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
    <div style="flex: 0 0 150px;">
        <img src="..\images\thumbnails\se3et.png" alt="SE3ET Thumbnail" style="width: 150px; height: auto;">
    </div>
    <div style="flex: 1; padding-left: 20px;">
        <h3>SE3ET: SE(3)-Equivariant Transformer for Low-Overlap Point Cloud Registration</h3>
        <p>
            Chien Erh Lin, 
            <strong>Minghan Zhu</strong>,
            Maani Ghaffari <br>
            <em>IEEE Robotics and Automation Letters, 2024</em>
        </p>
        <p>
            <a href="https://ieeexplore.ieee.org/abstract/document/10616262">Paper</a> | 
            <a href="https://github.com/UMich-CURLY/SE3ET">Code</a>  
            <!-- | <a href="link-to-bibtex">BibTeX</a> -->
        </p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
    <div style="flex: 0 0 150px;">
        <img src="..\images\thumbnails\lieneurons.png" alt="SE3ET Thumbnail" style="width: 150px; height: auto;">
    </div>
    <div style="flex: 1; padding-left: 20px;">
        <h3>Lie Neurons: Adjoint-Equivariant Neural Networks for Semisimple Lie Algebras</h3>
        <p>
            Tzu-Yuan Lin*, 
            <strong>Minghan Zhu*</strong>,
            Maani Ghaffari <br>
            <em>International Conference on Machine Learning (ICML), 2024</em>
        </p>
        <p>
            <a href="https://arxiv.org/pdf/2310.04521">Paper</a> | 
            <a href="https://github.com/UMich-CURLY/LieNeurons">Code</a>  
            <!-- | <a href="link-to-bibtex">BibTeX</a> -->
        </p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
    <div style="flex: 0 0 150px;">
        <img src="..\images\thumbnails\eq4d.png" alt="SE3ET Thumbnail" style="width: 150px; height: auto;">
    </div>
    <div style="flex: 1; padding-left: 20px;">
        <h3>4D Panoptic Segmentation as Invariant and Equivariant Field Prediction</h3>
        <p>
            <strong>Minghan Zhu</strong>, Shizhong Han, Hong Cai, Shubhankar Borse, Maani Ghaffari, Fatih Porikli <br>
            <em>IEEE/CVF International Conference on Computer Vision (ICCV), 2023</em>
        </p>
        <p>
            <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_4D_Panoptic_Segmentation_as_Invariant_and_Equivariant_Field_Prediction_ICCV_2023_paper.pdf">Paper</a> | 
            <a href="https://github.com/minghanz/EQ-4D-StOP">Code</a>  
            | <a href="https://eq-4d-panoptic.github.io/">Project</a>
        </p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
    <div style="flex: 0 0 150px;">
        <img src="..\images\thumbnails\e2pn.png" alt="SE3ET Thumbnail" style="width: 150px; height: auto;">
    </div>
    <div style="flex: 1; padding-left: 20px;">
        <h3>E2PN: Efficient SE(3)-Equivariant Point Network</h3>
        <p>
            <strong>Minghan Zhu</strong>, Maani Ghaffari, William A Clark, Huei Peng <br>
            <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023</em>
        </p>
        <p>
            <a href="https://arxiv.org/pdf/2206.05398">Paper</a> | 
            <a href="https://github.com/minghanz/E2PN">Code</a>  
            <!-- | <a href="https://eq-4d-panoptic.github.io/">Project</a> -->
        </p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
    <div style="flex: 0 0 150px;">
        <img src="..\images\thumbnails\monoedge.png" alt="SE3ET Thumbnail" style="width: 150px; height: auto;">
    </div>
    <div style="flex: 1; padding-left: 20px;">
        <h3>MonoEdge: Monocular 3D Object Detection Using Local Perspectives</h3>
        <p>
            <strong>Minghan Zhu</strong>, Lingting Ge, Panqu Wang, Huei Peng <br>
            <em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023</em>
        </p>
        <p>
            <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Zhu_MonoEdge_Monocular_3D_Object_Detection_Using_Local_Perspectives_WACV_2023_paper.pdf">Paper</a> 
            <!-- | <a href="https://github.com/minghanz/E2PN">Code</a>   -->
            <!-- | <a href="https://eq-4d-panoptic.github.io/">Project</a> -->
        </p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
    <div style="flex: 0 0 150px;">
        <img src="..\images\thumbnails\placerec.png" alt="SE3ET Thumbnail" style="width: 150px; height: auto;">
    </div>
    <div style="flex: 1; padding-left: 20px;">
        <h3>SE(3)-Equivariant Point Cloud-Based Place Recognition</h3>
        <p>
            Chien Erh Lin, Jingwei Song, Ray Zhang, <strong>Minghan Zhu</strong>, Maani Ghaffari <br>
            <em>Conference on Robot Learning (CoRL), 2022,</em>
        </p>
        <p>
            <a href="https://proceedings.mlr.press/v205/lin23a/lin23a.pdf">Paper</a> | 
            <a href="https://github.com/UMich-CURLY/se3_equivariant_place_recognition">Code</a>  
            <!-- | <a href="link-to-bibtex">BibTeX</a> -->
        </p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
    <div style="flex: 0 0 150px;">
        <img src="..\images\thumbnails\equivreg.png" alt="SE3ET Thumbnail" style="width: 150px; height: auto;">
    </div>
    <div style="flex: 1; padding-left: 20px;">
        <h3>Correspondence-Free Point Cloud Registration with
SO(3)-Equivariant Implicit Shape Representations</h3>
        <p>
            <strong>Minghan Zhu</strong>, Maani Ghaffari, Huei Peng <br>
            <em>Conference on Robot Learning (CoRL), 2021,</em>
        </p>
        <p>
            <a href="https://proceedings.mlr.press/v164/zhu22b/zhu22b.pdf">Paper</a> | 
            <a href="https://github.com/minghanz/EquivReg">Code</a>  
            <!-- | <a href="link-to-bibtex">BibTeX</a> -->
        </p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
    <div style="flex: 0 0 150px;">
        <img src="..\images\thumbnails\trafcam3d.png" alt="SE3ET Thumbnail" style="width: 150px; height: auto;">
    </div>
    <div style="flex: 1; padding-left: 20px;">
        <h3>Monocular 3D Vehicle Detection Using Uncalibrated Traffic Cameras through Homography</h3>
        <p>
            <strong>Minghan Zhu</strong>, Songan Zhang, Yuanxin Zhong, Pingping Lu, Huei Peng, John Lenneman <br>
            <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021</em>
        </p>
        <p>
            <a href="https://arxiv.org/pdf/2103.15293">Paper</a> | 
            <a href="https://github.com/minghanz/trafcam_3d">Code</a>  
            <!-- | <a href="link-to-bibtex">BibTeX</a> -->
        </p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 20px;">
    <div style="flex: 0 0 150px;">
        <img src="..\images\thumbnails\c3d.png" alt="SE3ET Thumbnail" style="width: 150px; height: auto;">
    </div>
    <div style="flex: 1; padding-left: 20px;">
        <h3>Monocular Depth Prediction through Continuous 3D Loss</h3>
        <p>
            <strong>Minghan Zhu</strong>, Maani Ghaffari, Yuanxin Zhong, Pingping Lu, Zhong Cao, Ryan M Eustice, Huei Peng <br>
            <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2020</em>
        </p>
        <p>
            <a href="https://arxiv.org/pdf/2003.09763">Paper</a> | 
            <a href="https://github.com/minghanz/c3d">Code</a>  
            <!-- | <a href="link-to-bibtex">BibTeX</a> -->
        </p>
    </div>
</div>
